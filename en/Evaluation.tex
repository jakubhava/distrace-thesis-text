\chapter{Evaluation}
\label{chap:evaluation}
This chapter firstly describes some known limitations of this tool. The further section shows the measurements of how long the application starts with and without the tracing enabled. These measurements are based on the H\textsubscript{2}O example. The final section points out the future plans of the Distrace tool.
\section{Known Limitations}
There are a few limitations at the moment in the thesis which we would like to address in the future.
\begin{itemize}
	\item \textbf{Required Java version} \newline
	Distrace requires Java 8 to be available. The platform has been tested on several Java 7 implementations and several internal Java bugs occurred. These problems are already fixed in the Java 8. Even though Java 7 is being replaced by Java 8, it still can be seen like a limitation of this tool.
	\item \textbf{Overriden \texttt{getResourceAsStream} method} \newline
	The instrumentation process requires that the \texttt{getResourceAsStream} is able to return class file for a class. However, developers may override the method and not provide the class files when we ask for them. When this happens and we are not able to load the class file using this method, another attempt to load the class file with different approach is done, however this is still a limitation of the Distrace tool.
	
	\item \textbf{Attaching Agent at Run-Time} \newline
	Currently, the native agent has to be attached prior the application start using the \texttt{-agentlib} or \texttt{-agentpath} options. However, Java provides the attachment API allowing the agents to join at run-time of the application. This has the benefit that the application can be started without any additional arguments. The thesis contains the sub-project called \textbf{agent-attacher}, which is using the attachment API and attaches the agent to the running application, but currently, the agent does not perform any tasks when attached at run-time.
	
	The agent is disabled for this use-case since we would need to properly handle and separate the instances of instrumented classes before and after the instrumentation. It is possible that an instance of some class have been created, then, the class has been instrumented, and new instances of this class have been created. Therefore we would have instances of the same class, first instrumented and the second not. This could be problem at some applications and still needs a further investigation whether this can be allowed in general or not.
	
\end{itemize}



\section{Measuring the Tool Overhead}
This sections measures the overhead of the Distrace tool on the H\textsubscript{2}O example. We measure how long the example run from the start to end when the agent was attached and monitoring enabled and also in the opposite case. This measurement is highly specific on the type of the example since it depends on several factors, such as number of classes being instrumented or whether we optimized the performance by adding the application classes on the instrumentation server classpath.

In this measurement, we will use instrumentation server which already has application classes on its classpath since it's the advice and most generic use-case of the tool. We will also run the example in the local instrumentation server mode, which means that each native agent starts the server for the local application automatically. The measurements have been performed on H\textsubscript{2}O cluster of size three with 16 GB memory available and Intel Core I7 quad-core CPU.

The following Table \ref{bench1} contains numbers in seconds how long it took to start the whole cluster of size 3, with and without the instrumentation enabled.

\begin{center}
	\begin{tabular}{ l l l }
		\hline
		Run Number & Monitoring off & Monitoring on \\ \hline
1 & 37,378s	& 40,912s	\\
2 & 30,699s & 50,104s	\\
3 & 36,902s & 45,844s	\\
4 & 36,709s	& 46,502s	\\
5 & 31,063s	& 47,503s	\\
6 & 30,799s &	50,440s	\\
7 & 36,799s &	44,695s	\\
8 & 37,358s	& 50,504s	\\
9 & 37,844s	& 47,444s	\\
10 & 36,969s	& 44,909s	\\
  \hline  
\textbf{average} & \textbf{35,252s} & \textbf{46,886s} \\
	\end{tabular}
	\captionof{table}{First measurementt.}\label{bench1}
\end{center}
We can see that in this case the average run time with monitoring enabled is on average 10 seconds slower. This can be explained as the overhead of starting the instrumentation server from the native agent on a single machine for all three H\textsubscript{2}O nodes in the cluster.

The following Table \ref{bench2} shows how long the only the computation of the  first map-reduce tasks lasted with monitoring enabled and disabled.

\begin{center}
	\begin{tabular}{ l l l }
		\hline
		Run Number & Monitoring off & Monitoring on \\ \hline
1	&12,232s&	16,810s  \\ 
2 	&12,359s &	14,467s \\ 
3	&12,293s &	15,681s \\ 
4	&12,331s &	13,196s \\ 
5	&12,229s &	11,055s \\ 
6	&12,360s &	15,037s \\ 
7 &	11,867s	&11,839s  \\ 
8	 &	12,399s &17,246s  \\ 
9&	12,256s 	&11,088s  \\ 
10	&12,323s &	15,500s \\ 

		\hline  
		\textbf{average} & \textbf{12,265s} & \textbf{14,192s} \\
	\end{tabular}
	\captionof{table}{Second measurement.}\label{bench2}
\end{center}

The overhead in case  the monitoring is enabled is caused by the instrumentation of the classes when they are first needed. We can also see that the variety is higher in when instrumentation is enabled. This may be explained as the variety in transferring the classes between the instrumentation server and the agent.

Lastly, the final Table \ref{bench3} shows how long each subsequent computation run, also in case when monitoring is enabled and disabled. This means that we omit the first map-reduce task computation and measure only following calls when all instrumentation has already finished for the required classes.
\begin{center}
	\begin{tabular}{ l l l }
		\hline
		Run Number & Monitoring off & Monitoring on \\ \hline
1&	2,025s&	3,279s \\ 
2&	2,025s&	4,143s \\
3&	2,030s	&3,153s \\
4&	1,079s&	4,225s \\
5&	1,025s&	3,653s \\
6&	1,071s	&3,367s \\
7	&0,990s&	3,055s \\
8&	1,064s	&2,659s \\
9&	0,264s&	3,254s \\
10&	0,999s&	2,721s \\

\hline  
\textbf{average} & \textbf{1,257s} & \textbf{3,351s} \\
\end{tabular}
\captionof{table}{Third measurement.}\label{bench3}

\end{center}

We can therefore see that there is still overhead by the introduced tool, but not significant. This is overhead is caused because we are doing some extra work introduced by the instrumentation such as checking whether we are closing the correct span or the overhead of exporting the span.
\section{Future plans}
This tool is planned to be extend in the future. Mainly, the tool should be improved in the following areas:
\begin{itemize}
\item \textbf{More Additional Span Exporters} \newline
Currently, the tool provides two default span exporters and allows the user to extend the \texttt{SpanExporter} abstract class and implement custom ones. However, we would like to create more exporters in the future, which would be able to store spans into different storage types and also in different formats. At this moment, the output is in the JSON format understandable to the Zipkin user interface and the data are exported either to disk or are send to the user interface right away. We could, for example, create a span exporter, which could export spans into a database. from which the arbitrary user interface could fetch the data.
\item \textbf{Support for Flame Graphs} \newline
The second future plan is to add support for flame charts. The native agent could be used to capture the stack-traces of the running application and later, a flame graph representing the distributed computation could be created. For example, this integration would give us the ability to inspect the memory-usage or performance cluster-vise using the flame graphs visualization.
\end{itemize}




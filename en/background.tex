\chapter{Background}
\label{chap:background}
This chapter covers technologies relevant to the thesis. It starts with an overview of similar monitoring tools for cluster-based applications and follows by short overview of tools used for debugging of large scale applications. Different approaches to applications profiling are described in the following part. 

In the next several sections the technologies considered to be used in Distrace or used in thesis are introduced. The sections cover libraries for bytecode manipulation, communication, logging and also cover important relevant parts of Java libraries such as JNI and JVMTI. Docker is briefly described at the end of this chapter as it is used as the main distribution package of the whole platform.

\section{Cluster Monitoring Tools}
The most significant and relevant platforms on which this thesis is based are Google Dapper and Zipkin. Both tools serve the same core purpose which is to monitor large-scale Java-based distributed applications. Zipkin is developed according to Google Dapper design which means that these two platforms share a few similar concepts. The basic concept shared between these two platforms is a concept called \textit{Span} and it is explained in more details in the following section in the meaning of this thesis. For now, a span can be though of as time slots encapsulating several calls from one node to another with well-defined start and end of the communication.

The following two sections describe the basics of the both mentioned platform. Since both Zipkin and Google Dapper shares some basic concepts, only relevant and interesting parts to the thesis of each platform are described.
\subsection{Google Dapper}
\label{dapper}
Google Dapper is proprietary software used at Google. It is mainly used as a tool for monitoring large distributed systems and helps with debugging and reasoning about applications performance running on multiple host at the same time. Parts of the monitored system does not have to be written in the same programming language. Google Dapper has three main pillars on which is built:
\begin{itemize}
	\item \textbf{Low overhead} \newline
	Google Dapper should share the same life-cycle as the monitored application itself to capture also the intermittent events thus low overhead is one of the main design goals of the tool.
	\item \textbf{Application level transparency} \newline
	The developers and users of the application should not know about the monitoring tool and are not supposed to change the way how they interact with the system when the monitoring tool is running. It can be assumed from the paper that achieving application level transparency at Google was easier than it could be in more diverse environments since all the code produced at the Google use the same libraries and share similar control flow practices.
	\item \textbf{Scalability} \newline
	Such a system should perform well on data of significantly large scale.
\end{itemize}	
Google Dapper collects the information from distributed applications as distributed traces. The origin of the distributed trace is the communication or task initiator and the trace spans across the nodes in the cluster which took part in the computation or communication.
	
There were two approaches proposed for obtaining the distributed traces when Google Dapper was developer: black-box and annotation-based monitoring approaches. The black-box approach assumes no additional knowledge about the application whereas the annotation-based approach can make use of additional information via annotations. Google Dapper is mainly using black-box monitoring schema since most of the control flow and RPC (Remote Procedure Call) subsystems are shared among Google, however support for custom annotations is provided via additional libraries build on top of core system. This gives the developer of an application possibility to attach additional information to spans which are very application-specific.
	
In google Dapper, distributed traces are represented as so called trace trees, where tree nodes are basic units of work referred to as spans. Spans are related to other spans via dependency edges. These edges represents relationship between parent span and children of this span. Usually the edges represents some kind of RPC calls or similar kind of communication. Each span has can be uniquely identified using its ID. In order to reconstruct the whole trace tree, the monitoring tool needs to be able to identify the Span where the computation started. Spans without parent id are called root spans and serves exactly this purpose. Spans can also contain information from multiple hosts, usually from direct neighborhood of the span. Structure of a span in Google Dapper platform is described in the figure \ref{fig:dapper_span}.
\begin{figure}
	\centering
		\includegraphics[scale=0.7]{dapper_span.png}
	\caption{Example of Span in Google Dapper. Picture taken from the Google Dapper paper}
	\label{fig:dapper_span}
\end{figure}

Google Dapper is able to follow distributed control paths thanks to instrumentation of a few common shared libraries among Google developers. This instrumentation is not visible to the final users of the system so the system has high-level of application transparency. The instrumentation points are:
\begin{itemize}
	\item Dapper attaches so called trace-context as thread-local variable to the thread when it handles any kind of control path. Trace context is small data structure containing mainly just reference to current and parent span via their ids.
	
	\item Dapper instruments the callback mechanism so when computation is deferred, the callbacks still carry around trace context of the creator and therefore also parent and current span ids.
	
	\item Most of the communication in Google is using single RPC framework with language bindings to different languages. This library is instrumented as well to achieve the desired transparency.
\end{itemize}

Sampling of the captured data has also a positive effect on the low-level overhead of the whole application. As mentioned in the paper, the volume of data processed at Google is significant so only samples are taken at a time.

\subsection{Zipkin}
\label{zipkin}
Zipkin is an open-source distributed tracing system. It is based on Google Dapper technical paper and manages both the collection and lookup of captured data. Zipkin uses instrumentation and annotations for capturing the data. Some
information are recorded automatically, for example time when Span was created, whereas some information are optional. Zipkin has also support for custom application-specific annotations.

Zipkin architecture can bee seen on figure \ref{fig:zipkin_architecture}.
\begin{figure}
	\centering
	\includegraphics[scale=0.6]{zipkin_architecture.png}
	\caption{Zipkin architecture - http://zipkin.io/pages/architecture.html}
	\label{fig:zipkin_architecture}
\end{figure}
The instrumented application is responsible for creating valid traces. For that reason, Zipkin has set of pre-instrumented libraries ready to be used in order to work well with the whole Zipkin infrastructure. Spans are stored asynchronously in Zipkin to ensure lower overhead. Once a span is created, it is sent to Zipkin collector. In General, Zipkin consists of 4 components:
\begin{itemize}
	\item \textbf{Zipkin Collector} \newline
	The collector is usually a daemon thread or process which stores, validates and indexes the data for future lockups.
	\item\textbf{Storage} \newline
	Data in Zipkin can be stored in a multiple ways, so this is a pluggable component. Data can be stored for example in Cassandra, MySQL or can be send to Zipkin UI right away without any intermediate storage at all. The last option is good for small amount of data since the user interface is not supposed to handle data storage.
	\item \textbf{Zipkin Query Service} \newline
	This component acts as a query daemon allowing the user to query various information about span using simple JSON API.
	\item \textbf{Web UI} \newline
	Basic, but very useful user interface. It allows the user to see whole trace trees and all spans with dependencies between them. The user interface accepts the spans in JSON format.
\end{itemize}
The Zipkin Web UI is used as front-end for the monitoring tool developed on this thesis. More information how it is used in the thesis is described in more detail in \hyperref[sec:zipkin_ui]{Zipkin UI} section of \hyperref[chap:design]{Design} chapter.
 \section{HTrace}
 \label{htrace}
 HTrace https://github.com/cloudera/htrace is a tracing framework created by Cloudera used for monitoring distributed systems written in Java. It is based on Google Dapper as well and shares the same concepts as Spans and Traces. In order to allow tracing of the application, the users need to manually attach Span identifiers to desired RPC's (Remote Procedure Calls). These identifiers are then used to create relationships between spans collected on different nodes. HTrace stores the Span and Trace information in thread-local storage and the user is responsible for making sure this state is transferred to a new thread. Htrace has also support for custom Spans and annotations and thus allows the user to collect application specific information as part of the Spans. 
 
 The disadvantage of this tool is the need for instrumenting the monitored application in order to allow the tracing and spans collection.
\section{Tools for Large-Scale Debugging}
Standard techniques and tools can be used for debugging distributed applications, however the main purpose of these tool is to debug a single node applications and therefore when applying them on nodes in the distributed application the information about dependencies between different nodes in the cluster is not available. Many tools for large-scale debugging exist, but this section just points out basic ideas behind two different approaches - discovering scaling bugs and behavior based debugging. 

\subsection{Discovering Scaling Bugs}
The scalability is one of the most important aspects of distributed systems. It is desired to know how the platform scales when it process significantly big data and what is the expected scalability trend. It can happen that the platform can run significantly slower on big data than expected when tested on smaller data. This issue is usually called a scaling bug. Tools which can be used to help discovering scaling bugs are for example Krishna and WuKong. Both of the mention tools are based on the same idea. They build a scaling trend based on data batches of smaller size and the observed scaling trend acts as a boundary. The scaling bug becomes observable when the scaling trend is violated. The first tool, Wrishna, is not able to distinguish which part of the program violated the scaling trend. This is however possible in the second tool, WuKong. In comparison to Krishna, Wukong does not build one scaling trend of the whole application, but creates more smaller models, each per some control flow structure in desired programming language. All these smaller models represent together the whole scaling trend. When the application observes the scalling bug, WuKong is able to locate us in the place in the code where the trend is probably violated.

\subsection{Behavior-based Analysis}
The second category of tools used for debugging large scale applications are based on behavior analysis. The basic idea behind these tools is creation of classes of equivalence from different runs and processes of the application. Using this approach the amount of data used for further inspection is lowed down. These tools are especially helpful when discovering anomalies between different observed application runs. For example, STAT - Stack Trace Analysis Tool, is a lightweight and scalable debugging tool used for identifying errors on massive high performance computing platforms. It gathers stack traces from all parallel executions, merges together stacktraces from different processes that have the same calling sequence and based on that creates equivalence classes which make it easier for debugging highly parallel applications. 
The other tool used as an example in this category is AutomaDed. This tool creates several models from an application run and can compare them using clustering algorithm with (dis)-similarity metric to discover anomalous behavior. It can also point to specific code region which may be causing the anomaly.

\section{Profiling Tools}
Profiling is a form of dynamic code analysis. It may be used for example for determining how long each part of the system takes compared to the time of whole application run or for example to determine which part of the application uses the most memory. Profiling tools can be divided in two categories:
\begin{itemize}
	\item \textbf{Sampling Profilers} \newline
Sampling profilers take statistical samples of an application at well-defined points such as method invocations. The points where the application should take samples have to be inserted at the compilation time by the compiler. Sampling profilers usually have less overhead compared to instrumentation profilers. These profiles are good to collect for example time how long a method run, caller of the method or for example the complete stacktrace. However they are not able to collect any application specific information.
	\item \textbf{Instrumentation Profilers} \newline
This can be solved by instrumentation profilers. These profilers are based on the instrumentation of the application's source code. They record the same kind of information as the sampling profilers and usually give the developer the ability to specify extra points in the code where the application specific data ar recorded. Compared to sampling profilers, instrumentation profilers usually have slightly worse performance.
\end{itemize}

However, profilers can be also looked at from different point of view and categorized based on the level on which they operate and are able to record the information.
\begin{itemize}
	\item \textbf{System Profilers} \newline
	System profilers operate on operating system level. They can show system code paths, but are not able to capture method calls done for example in Java application.
	\item \textbf{Application Specific Profilers} \newline
	Generally, application specific profilers are able to collect method calls within the application. For example, JVM profilers can show Java stack traces but are not able to show the further call sequence on the operating system level.

\end{itemize}
The ideal solution for monitoring purposes of Java applications would be to have information from both kind of profilers, however combining outputs of these profiler types is not straightforward. The profilers which are able to collect traces from both system and JVM profilers are usually called mixed-mode profilers. JDK8u60 comes with the solution in a form of extra JVM argument \textit{-XX:+PreserveFramePointer} \cite{MixedModeProfilers}.  Operating system is usually using this field to point to the most recent call on the stack frame and system profilers make uses of this field. In case of Java, compilers and virtual machines don't need to use this field since they are able to calculate the offset of the latest stack frame from the stack pointer. This leaves this register available for various kind of JVM optimizations. The \textit{-XX:+PreserveFramePointer}  option ensures that JVM abides the frame pointer register and will not use it as a general purpose register. Therefore, both system and JVM stack frames can appear in single call hierarchy. Using the JVM mixed-mode profilers we are able to collect stack traced leading to:
\begin{itemize}
	\item \textbf{Page Faults} - these traces are useful to show what JVM code triggered main memory to grow.
	\item \textbf{Context Switches} - these traces are used to determine code paths which often lead to CPU switches.
	\item\textbf{Disk I/O Requests} - these traces show code paths leading to IO operations such as blocking disk seek operation.
	\item \textbf{TCP Events} - these traces show code paths going from high-level Java code to low-level system methods such as \texttt{connect} or\texttt{ accept}. They can be used to reason about performance and good design of network communication in much more better detail.
	\item \textbf{CPU Cache Misses} - these traces show code paths leading to cache misses. This information can be used to optimize the Java code to make better use of the existing cache hierarchy.
\end{itemize}

All the information bellow can be described on a special chart called Flame charts.
\subsubsection{Flame Graphs}
Flame Graphs are special graphs introduced developer Brendan Gregg. Flame graphs are visualization for sampled stack traces, which allows the hot paths in the code to be identified quickly. The output of sampling or instrumentation profiler can be significantly big and therefore visualizing can help to reason about performance in more comfortable way. 

\begin{figure}
	\centering
	\includegraphics[scale=0.35]{flame_chart.png}
	\caption{Flame Graph example}
	\label{fig:flame_chart}
\end{figure}
Flame graph is a graph where:
\begin{itemize}
	\item Each box represents a function call in the stack.
	\item The \textbf{y-axis} shows stack frame depth. The top function is the function which was at the moment of capturing this flame chart on the CPU. All functions underneath of it are its ancestors.
	\item The \textbf{x-axis} shows the population of traces. It doesn't represent passage of time. The function calls are usually sorted alphabetically.
	\item The width of each box represents the time how long the function was on CPU.
	\item The colors are not significant, they are just used to visually separate different function calls.
\end{itemize}

Flame charts can be created in a few simple steps, but it depends on the type of profiler the user wants to use. 
\begin{enumerate}
	\item Capture stack traces. For this step the profiler of custom choice may be used.
	\item Fold stacks. The stacks need to be prepared so Flame graphs can be created out of them. Scripts for most of the major profilers exist and may be used to prepare the folded stack trace.
	\item Generate the flame graph itself again using the helper script.
\end{enumerate}

The purpose of this really short section is just to introduce the idea of Flame charts because it's one of the future plans to add support for flame charts into to monitored tools developed by this thesis. For more information about the flame charts please visit the Brendan Gregg's blog.
\section{Byte Code Manipulation Libraries}
The thesis highly depends on the Java bytecode instrumentation and this section gives overview of four bytecode manipulation libraries considered to be used at the thesis:  Javassist, Byte Buddy, CGlib and. Since it's a core feature of the whole platform and affects both the performance and the usability of the whole platform, the library was thoroughly reviewed before selected. Byte Buddy library was selected and is therefore described in more detail. However the reasons for its selection can be found in the following \hyperref[analysis]{Analysis} section.

\subsection{ASM}
\label{asm}
ASM is a low-level high-performance Java bytecode manipulation framework. It can be used to dynamically create new classes or redefined already existing classes. It works on the bytecode level so the user of this library is expected to understand the JVM bytecode in detail. ASM operates on event-driven model as it makes use of Visitor design pattern to walk through complex bytecode structures. ASM defines some default visitors such as \textit{FieldVisitor}, \textit{MethodVisitor} or \textit{ClassVisitor}. The ASM project can be a great fit for project requiring a full control over the bytecode creation or inspection since it's low-level nature.
\subsection{Javassist}
\label{javassist}
Javassist is well-known bytecode manipulation library built on top of ASM. It allows the Java programs to define new classes at run-time and also to modify class files prior the JVM loads them. It works on higher level of abstraction compared to ASM so the user of this library is not required to work with the low-level bytecode. The advantage of Javassist is that the injected code does not depend on the Javassist library at all. The code to be injected to the existing bytecode is expressed as Java Strings. The disadvantage of this approach is that the the code to be injected is not subject to code inspection in most of the current IDEs. The strings representing the code are compiled at run-time by special Javassist compiler. This run-time compilation works well for most of the common programming structures but for example auto-boxing and generics are not supported by the compiler. Also it is important to mention that Javassist does not have support for the code injection itself. Therefore, it can be used for specifying the code which alters the original code but external tool needs to be used to inject the code itself.
\subsection{CGLib}
\label{cglib}
CGLib as another byte-code manupulation library built on top of ASM. The main concepts are build around `Enhancer` class which is used to create proxies by dynamically extending classes at run-time. The proxified class is then used to intercept method calls and the result of previous methods or fields as we define. However CGLib lacks comprehensive documentation making harder to even understand the basics.

\subsection{Byte Buddy}
\label{sec:byte_buddy}
Byte Buddy is fairly new, light-weight and high-level bytecode manipulation library. The library depends only on visitor API of the ASM library which does not further have any other dependencies. It does not require from the user to understand format of java bytecode but despite this, it gives the users full flexibility to redefine the bytecode according to their specific needs. Also, classes created or instrumented by Byte Buddy does not depend on the Byte Buddy framework. Despite it's high-level approach, it still offers great performance and is used at frameworks such as Mockito or Hibernate. Byte Buddy can be used for both code generation and transformation of existing code.

\subsubsection{Code Generation}
Code generation is done by specifying from which class a new class should be sub-classing. In the most generic case, class can be created based on the \texttt{Object} class. The newly created class can introduce new methods or intercept methods from it's super class. In order to intercept existing methods (change their behavior and return value), the method to be intercepted has to be identified using so-called \texttt{ElementMatchers}. These matchers allow the developer to identify methods using for example their names, number of arguments, return types or associated annotations. The whole list of matchers and also examples how code can be generated is greatly described in the documentation of the Byte Buddy library.

The power behind Byte Buddy is also that it can be used to redefine classes at run-time. This is achieved by several concepts, mainly via Transformers, Interceptors and Advice API.
\subsubsection{Code Transformation}
In order to tell Byte Buddy what method or field to intercept, the place in code which triggers the interception has to be identified. First,  a class containing the desired method for instrumentation needs to be located. It can be done by simply specifying the class name or using more complex structures. For example, the element marchers may be used to only consider all classes A extending class B whilst implementing interface C at the same type. 

The next step is to define the \texttt{Transformer} class itself. Transformers are used to identify methods in the class which should be instrumented and they also specify the class responsible for the instrumentation itself. This class may be either Interceptor or Advice and their description is given in more detail in the following section. 

The methods to be instrumented can specified in the transformer using the element matchers. In more detail, \texttt{Transformer} interface has a method \texttt{ transform} which has \texttt{DynamicType.Builder} as it's argument. This builder is used to create a single transformer wrapping all the transformers for all classes in the code so the result of this builder can be thought of as a dispatcher of the instrumentation for complete application.

There are two ways how to instrument a class in Byte Buddy. Either via Interceptors or via Advice API.
\subsubsection{Interceptors}
Interceptor is a class defining the new or changed desired behavior for the method to be instrumented. 
The demonstration how Byte Buddy uses interceptors is shown on a small example. Let's assume the class \texttt{Foo} is the original unchanged class:
\begin{lstlisting}[language=Java]
class Foo {
	String bar() {
		return "bar"; 
	}
}
\end{lstlisting}
	
Le'ts also assume that the Interceptor is of type \texttt{Qux}. The interception of the class \texttt{Foo} using the defined interceptor looks like this in schematic code:

\begin{lstlisting}[language=Java]
class Foo {
	// Requires your interceptor class to be known
	static Qux $interceptor;
	String bar() {
		return $interceptor.intercept(); 
	}
	static {
		// Requires knowing the framework
		$interceptor = ByteBuddyFramework.defineField(Foo.class);
	}
}
\end{lstlisting}
		
It can therefore be seen that in case of interceptors, Byte Buddy does not inline the bytecode to the \texttt{Foo} class but requires the interceptor class to be available on the machine where the instrumentation takes place. Also the interceptor field needs to be initialized, which is in this case done in the static initializer. The initialization of interceptors is done using special helper class called \texttt{LoadedTypeInitializer}.

There are multiple ways how this behavior can be changed:
\begin{enumerate}
\item In Byte Buddy, the initialization strategy can be modified accordingly to the specific needs. No-op strategy can be used and \texttt{LoadedTypeInitializer} can be read right before the class is about to be instrumented.  The initialization of the interceptor field can be handled manually later using observed initializer or we can even serialize the initializer together with the \texttt{Qux} \texttt{Interceptor} class, send them to different JVM where the instrumentation should take place and manually initialize the the interceptor field.
\item Instead of referring to \texttt{Qux} as a instance, it can delegated to as instance of \texttt{Qux} class. In this case the interception is performed via static methods and no intializers are required to be available, however the interceptor class still needs to be known at run-time.
\item Instead of using interceptors, advice API which in-lines the code to the class itself may be used.
\end{enumerate}
\subsubsection{Advice API}
Advices are another approach how code can be instrumented in Byte Buddy. This approach is more limited compared to the interceptors, but in cases where it's possible to use it, the code is in-lined into the original class's bytecode and therefore no other dependencies are required. It is also stated in Byte Buddy documentation that performance of Advice API is better compared to the performance if interceptors.
However, the instrumentation using Advice API is only allowed before or after the matched method. This is achieved using the \texttt{Advice.onMethodEnter} and \texttt{Advice.onMethodExit} annotations.

\section{Communication Middleware}
This thesis consist of several parts written in different languages which need be able to communicate. In order to achieve communication in such an environment, following libraries have been inspected.
\subsection{Raw Sockets}
\label{raw_sockets}
It this case raw sockets is not a library but it is referred to as using raw sockets on their low-level API. Using raw sockets has several pros and cos. It give the user full flexibility and the highest possible performance since there isn't any additional layer between the application data and the socket itself. However, integrating different platforms and different languages can be time consuming. Several frameworks have already been created to hide the implementation details of specific platforms so the user does not need to know about the language or underlying platform.
\subsection{ZeroMQ}
\label{zeromq}
ZeroMq is a communication library built on top of raw sockets. The core of the library is written in C++ however binding into different languages exist. The library is able transport messages inside a single process, between different processes on the same node or transfer messages over the network using TCP or also using multicast. The library also allows the user to create typologies using one of the many supported communication patterns. For example,  publisher-subscriber or request-reply patterns are supported. The library has several benefits compared to raw sockets:
\begin{itemize}
	\item Hiding the differences between underlying operating systems.
	\item Message framing - delivering whole messages instead of stream of bytes.
	\item Automatic message queuing. The internals take care of ensuring the messages are sent and received in correct order. The user can send the messages without knowing whether there are other messages in the queue or not.
	\item Language mappings to different languages.
	\item Ability to create different topologies. Example of a topology can be that one socket can be connected to multiple endpoints.
	\item Automatic TCP re-connection
	\item Zero-copy
\end{itemize}
\subsubsection{Zero-copy in ZeroMQ}
The library tries to apply concept called zero-copy whenever possible. When high-performance is expected from a system or network, copying of data is usually considered harmful and should be minimized as possible. The technique of avoiding copies of data is known as zero-copy.

Example of data copying can be transferring data from memory to network interface or from user application to underlying kernel.  It  can be seen that zero-copy can't be implemented at all layers. For instance,  without copying the data from the kernel to network interface, no data could be actually exchanged. However, ZeroMQ can achieve zero-copy at least on the application message level so the users can create ZeroMQ messages from their data without any copying which is a big performance benefit.
\subsection{NanoMsg}
\label{nanomsg}
NanoMsg [http://nanomsg.org/documentation-zeromq.html] is a socket library shadowing the differences between the underlying operation systems. It offers several communication patterns, is implemented on C and does not have any other dependencies. Generally, it offers very similar features to ZeroMQ since it's heavily based on it.

Unlike ZeroMQ, Nanomsg matches the full POSIX compliance. The author of the library states, that since it's implemented in C, the number of memory allocations is drastically reduced compared to c++, where, for example, C++ STL containers are used  Also compared to ZeroMQ, objects are not tightly bound to particular threads. This gives the user flexibility to create their custom threading models without significant limitations. NanoMsg also implements zero-copy technique at additional layers which again leads to performance benefits compared to ZeroMQ.

As in ZeroMQ, NanoMsq supports the following transport mechanisms:
\begin{itemize}
	\item \textbf{INPROC} \newline
	Inter process communication is used for transporting messages withing a single process, for example between different threads. In-process address is arbitrary case-sensitive string starting with \texttt{inproc://}.
	\item \textbf{IPC}  \newline 
	Inter processes communication allows several processes to communicate on the same node. The implementation uses native IPC mechanism available on the target platform. On Unix-like systems, IPC addresses are just references to files where both absolute and relative path can be used. The application has to have appropriate rights to read and write from the IPC file in order to allow the communication. On Windows, the named pipes are used. The address can be arbitrary case-sensitive string containing any character except the backslash. On both mentioned platforms, the address has to start with the \texttt{ipc://} prefix.
	\item \textbf{TCP} \newline
	TCP is used to transport messages in reliable manner to a single recipient in a reachable network.  The address in format \texttt{tcp://interface:port} needs to used when connecting to a node and when binding a node to specific address, the address in format \texttt{tcp://*:port} needs be used.
\end{itemize}

NanoMsg can be used via it's core C library, but several language mappings for different languages exist as well which makes working with the library easier.
\subsubsection{C++11 Mapping}
Nanomsgxx [https://github.com/achille-roussel/nanomsgxx] is a C++11 mapping for Nanomsg library. It is a small layer build on top of the core library making the API more C++11  friendly. Especially, there is no need to explicitly tell when to release resources, since it's handled automatically in descriptors. The \texttt{nnxx::message} abstraction over NanoMsg \texttt{nn::message} automatically manages buffers for zero-copy and also errors are reported using the exceptions which are sub-classes from \texttt{std::system\_error}
\subsubsection{Java Mapping}
Several Java bindings of Nanomsg library exists, but just jnanomsg library [http://niwinz.github.io/jnanomsg/latest/] is described here. This language binding is build on top of JNA (Java Native Access) library. It offers all the functionalities offered by the core library but also introduces non-blocking sockets exposed via a callback interface.

\section{Java Libraries}
This section describes some fundamental Java related libraries and technologies on which this thesis heavily depends. Firstly, Java Virtual Machine Tool Interface (JVMTI) is described, followed by the basic introduction to the Java Native Interface. Important Java concepts and classes relevant to the thesis are described in the following few sections.
\subsection{JVMTI}
\label{JVMTI}
The JVM Tool Interface [https://docs.oracle.com/javase/7/docs/platform/jvmti/jvmti.html] is an interface used by development and monitoring tools for communication with JVM. It allows the user to monitor and control the the application running in Java virtual machine. An application communicating with the JVM using JVMTI is usually called an agent. Agents are notified via events happening inside JVM and can react upon them. Agents run in the same process as the application itself which reduces the delay of the communication between the application and the agent. Since JVMTI is an interface written in C, agents can be written in C or C++. 

JVMTI supports 2 modes how an agent can can be started.  It can be either in \textbf{OnLoad} phase or in \texttt{Live} phase. In the \textbf{OnLoad} phase, the client is started together with the application and agent location can be specified using 2 arguments:
\begin{itemize}
	\item \texttt{-agentlib:<agent-lib-name>=<options>} \newline
	In this case, the library name to load is specified and it is loaded using platform specific manner .
	\item \texttt{-agentpath:<path-to-agent>=<options>} \newline
	In this case, the path to a location of the library is specified and the library is loaded from there.
\end{itemize}

In the \textbf{Live} phase, the agent is dynamically attached to running application. This approach is more flexible since it is not required to to specify the agent library to monitored application in advance. However it brings several limitations as well.

The goal of this section is not to describe full JVMTI functionality but just give the reader a brief introduction to the interface. For more details about JVMTI please visit the official documentation. The following sections try to very briefly describe the important parts of JVMTI relevant to the thesis.

\subsubsection{JVMTI Agent Initialization}
\label{subsec:jvmti_init}
When client is started, the method \newline \texttt{Agent\_OnLoad(JavaVM *jvm, char *options, void *reserved)} is called. This method should usually contain the agent custom initialization. Usually the agent initialization consist of several phases:
\begin{enumerate}
	\item Optionally, parse arguments passed to the JVMTI agent.
	\item Initialize JVMTI environment in order to be able to communicate with the observed application. JVMTI does not handle threads switches automatically, so proper locking and thread management fully depends on the user code.
	\item Register capabilities of the JVMTI agent. The capabilities specify what are the operations the JVMTI agent can perform. The agent can be, for example, allowed to re-transform classes or react to different class hook events.
	\item Register events the agent should react to. JVMTI does not inform the agent about all events by default, the events has to be manually defined.
	\item Register callbacks for the events the agent is interested in. Even though the JVMTI supports more events, the interesting events are: \texttt{cbClassLoad}, \texttt{cbClassPrepare}, \texttt{cbClassFileLoadHook}, \texttt{callbackVMInit} and \texttt{callbackVMDeath}.
	\item Optionally, initializing phase is also good for creating locks which may be later used for synchronization between different JVMTI threads.
\end{enumerate}

The user of JVMTI is also required to manually implement queuing and locking when processing multiple JVMTI events at the same time since the framework is not designed to handle these cases. http://www.oracle.com/technetwork/articles/java/jvmpitransition-138768.html
\subsubsection{JVMTI basic callbacks}
As mentioned above, there are several events sent from the observed application. When instrumenting the applications code, the following are the most important events to record:
\begin{itemize}
	\item \texttt{cbClassLoad} - triggered when class has been loaded by target JVM
	\item \texttt{cbClassPrepare} - triggered when class has been prepared by target JVM. All static fields, methods and implemented interfaces are available at this point but no code has been executed at this phase.
	\item \texttt{cbClassFileLoadHook} - triggered when virtual machine obtains class file data but before the class is loaded. Usually, class instrumentation is based on this hook since the callback contains field for the to changed byte-code passed for further loading.
	\item  \texttt{callbackVMInit} - triggered when virtual machine is initialized.
	\item  \texttt{callbackVMDeath} - triggered when virtual machine has been closed. This event is triggered in both planned and forcible stop.
\end{itemize}

\subsection{JNI}
\label{JNI}
Java Native Interface is a framework which allows Java code running in Java Virtual Machine to call native applications ( usually written in C or C++ ). It also allows native applications to access and call Java methods. All JNI operations require instance of class \texttt{JNIEnv}. This environment keeps the connection to the virtual machine. When calling a Java method from the native application, the correct method has to be first found. This is achieved by specifying  the types and method signature of the method.
\subsubsection{Java Types Mapping}
For each Java primitive type there is a corresponding native type in JNI. Native types always start with the \textbf{j} as the prefix, for example \texttt{boolean} is Java type whereas \texttt{jboolean} as a native type.
All other JNI reference types are referred to via \texttt{jobject} class. This means that java arrays are accessed via \texttt{jobject} since at this level they are referred to as Java objects. The most important question is how the types in method signatures can be specified. There is a mapping assigning each type a signature is used exactly for this purpose. The following table is based on http://docs.oracle.com/javase/7/docs/technotes/guides/jni/spec/types.html. and describes the mapping in detail:
\begin{center}
\begin{tabular}{ l l }
	  \hline
	  Type Signature & Java Type \\ \hline
	Z & boolean \\
	B & byte \\
	C & char \\
	S & short \\
	I & int \\
	J & long \\
	F & float \\
	L fully-qualified-class ; & fully-qualified-class \\
	{[} type & type{[]}\ \\
	( arg-types ) ret-type & method type \\
\end{tabular}
\end{center}

For example, the method: \newline \texttt{xx.yy.Person foo(int n; boolean[] arr, String s);} has the following signature:
\texttt{(I[ZLjava/lang/String;])Lxx/yy/Person;}

Note that in JNI, the elements in fully qualified class name are separated by slashes instead of dots.
\subsubsection{Example JNI Method Call}
The method bellow demonstrates how JNI can be used to call a Java method \texttt{getClassLoader} from the native environment.

\begin{lstlisting}[language=c++]
        jobject getClassLoaderForClass(JNIEnv *jni, jclass clazz){
        // Get the class object's class descriptor
        // (jclass inherits from jobject)
        jclass clsClazz = jni->GetObjectClass(clazz);
        // Find the getClassLoader() method in the class object
        jmethodID methodId = jni->GetMethodID(	clsClazz,
																         "getClassLoader",
																         "()Ljava/lang/ClassLoader;");
        return (jobject) jni->CallObjectMethod(clazz, methodId);
        }
\end{lstlisting}

It can be seen that the reference to the method needs to be obtained at first. This reference is use later for the invocation itself. From performance reasons, it's good practice to cache the references to Java methods or objects which are accessed from JNI often, since getting the reference has some initial overhead.

\subsection{Relevant Aspects of the  Java Language}
This section covers selected areas of the Java programming language relevant to the thesis. It briefly describes the class loading process for dynamically loaded classes. This is followed by explanation of two important class loaders relevant to the thesis and lastly, \texttt{ServiceLoader} class is shortly described.
\subsubsection{Class Loading Process}
Java allows program to load classes dynamically at run-time. This is achieved by a following process:
\begin{enumerate}
	\item \textbf{Loading} - Load the bytecode from a class file.
	\item \textbf{Linking} - Linking is the process of incorporating a new class to the run-time state of the JVM. This phase consists of 3 sub-phases:
	\begin{enumerate}
		\item \textbf{Verification} - Ensure that type in the binary format is correct and respects JVM restrictions.
		\item \textbf{Preparation} - This phase consist of allocation the memory for fields inside the loaded type.
		\item \textbf{Resolution} - This phase is optional ( depends on JVM implementation ). Resolution is the process of transformation symbolic references in the type's constant pool into direct references. The implementation may decide to behave in lazy way and delay resolution for the time when the type is accessed for the first time. Constant pool contains all references to variables and methods found during the compilation time at he class file.
	\end{enumerate}
	\item \textbf{Linking Phase} - class variables are initialized to initial values
\end{enumerate}
\subsubsection{Relevant Class Loaders}
There are several class loaders used natively in Java. This section however describes only two which are referenced later in the thesis. 

\begin{itemize}
	\item\textbf{Bootstrap class loader} \newline
	This class loader is used to load system classes. When using native agent, even classes loaded by bootstrap class loader can be instrumented and thus behavior of standard Java classes can be changed.
	
	\item  \textbf{sun.reflect.DelegatingClassLoader} \newline
	This class loader is used on the Sun JVM as the effect of a mechanism called \textit{inflation}. Usually reflective access to method or fields is initially performed via JNI calls. When Sun JVM determines that there is a repetition in calling the same method or the same field via JNI ( reflection), it creates synthetic class ( classes created dynamically at run-time), which is used to perform this call without the JNI. This has initial speed overhead, but at the end it speeds up the reflection calls. The classes created for this purpose are loaded and managed by exactly this class loader. 
\end{itemize}
\subsubsection{ServiceLoader Class}
\texttt{ServiceLoader} class is used to locate and load service providers. Service provider is an implementation of a service which is usually defined as set of methods inside an abstract class or interface. 

Service loader is used to load specific service providers at run-time. The group of service providers to be loaded can be specified via the service type ( interface or abstract class). The available service providers have to be defined in the META-INF folder of the application's jar distribution. For example, image there is a service A and two implementations, \texttt{Impl1} and \texttt{Impl2}. In that case META-INF folder should contain text file named A containing lines:
\begin{center}
\texttt{Impl1} \newline
\texttt{Impl1}  \newline
\end{center}
Service loaders can therefore be used to extend the application capabilities without changing the source code. When a new implementation of the service should be supported, it just needs to be registered inside the META-INF folder and the application will automatically use the new service provider together with the rest of the defined service providers defined earlier.
\section{Logging Libraries}
One of the key aspects of the developed platform is low-overhead. Logging can have negative effect on the performance of the application but sometimes it's necessary to have information from various application runs to be able to locate bugs or discover wrong configuration. Since one of the thesis's requirements is low-overhead, the selection of logging library is important for the performance of the thesis as well. 

Spdlog is a written in C++11, fast, header only logging library on which this project is based on. It allows both synchronous and asynchronous logging and custom message formatting.
\section{Docker}
Docker is an open source project used to pack, ship and run any application as a lightweight container [citate]. It is used to package applications in prepared environments so the user does not need to worry about configuration and downloading the correct dependencies for the application. 

Docker Compose is an extension built on top of docker allowing the user to specify multi-container startup-script. This script can define dependencies between different containers which leads to a simple and automated way how to start a group of related applications in separated environments using one single call. 


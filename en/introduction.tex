\chapter{Introduction}
Lately, the volume of data applications need to handle is significantly increasing. In order to support this scaling trend, the applications are becoming distributed for reasons of scalability, stability and availability. Not every task may be solved efficiently by distributed applications, however when it comes to big data, the computational requirements may be higher than single physical node can fulfill. Such distributed applications may run on multiple physical or virtual machines in order to achieve the best performance and the ability to process data significantly large. For this, computation clusters are created where the user interacts with the application as it would be running locally and the cluster should handle the distributed computation internally.

However, with growth of distributed applications there is also increasing demand for monitoring and debugging such applications. Analyzing applications in distributed environment is inherently more complex task comparing to single-node applications where well-known debugging and profiling techniques may be used. Analysis of single-node applications usually focuses on a single standalone applications where most of the information required to reason about it is collected directly from the application. In case of distributed application it is desired to collect the same information as on single-node applications plus, and more importantly, the shared state between the communicating nodes. For instance, an error may occur on one of the computation nodes in the cluster and over time, more and more nodes can become affected. By collecting the relations between the nodes, the analysis tool may be able to use the information to determine where the error initially occurred and how it spread over the time. 

Simple solution comes to mind to address this issue. Monitoring or debugging tools used for single-node applications may be attached per each application node and collect the information from the nodes separately on each other. This solution does not require any additional tools however the state between the application nodes would not be preserved unless the monitored application is already designed to send the required information. Most of the applications is not designed to transfer the information used for analysis of the application itself for several reasons. It may be hard or unwanted to design the application in a way that all the information required for analysis are already transferred between communication nodes. New analysis method may require new metrics which in this case would also mean recompiling and new deployment of the application.

For this reason several new monitoring and debugging tools have been developed. These tools are usually built on the code instrumentation technique. This method is used to alter the monitored application's code at run-time in order to collect all relevant information. The significant advantage of this method is that the original application does not have to be changed in order to add additional metrics. Usually, such tools use the instrumentation technique to add special information to the code that is later used to build a so-called distributed stack-trace.  A stack-trace in single node application represents the call hierarchy of a method at the given moment. Distributed stack-trace is a very similar concept except that the dependencies between different nodes are preserved and can be seen on the collected stack-trace as well. Therefore, distributed stack-traces give the possibility to see the desired relations between the applications node. Google Dapper and OpenZipkin are the most significant available monitoring tools and are discussed later in the thesis. 


\section{Project Goals}
This thesis introduces Distrace, a monitoring tool with the similar purpose, sharing some of the concepts mentioned above, however the goals of this work are different and should give the user a new generic and high-performance way how to monitor distributed applications. Main goals of the thesis are to create an open-source generic monitoring library with small footprint on the monitored applications whilst giving the user the possibility to use high-level programming language to define instrumentation points.

Main requirements for the platform are:
\begin{itemize}
	\item \textbf{Small Footprint} \newline
	 The mentioned cluster monitoring tools can affect the application performance and memory consumption since they perform instrumentation in the same virtual machine as the monitored application. The project is required to have a minimal footprint on the monitored application. The instrumentation is needed in order to inject special information about spans to the application's code, where spans are structures used to collect the shared state between the application nodes. This information is later used for span collection and associating the relationships between spans.
	\item \textbf{Application-level Transparency and Universality} \newline
	These two requirements are contradictory to each other. The universal tool which could be used for monitoring of majority of applications would either collect just basic information shared about all applications or the user would be required to manually specify the information to be collected specific to the application, which leads to loose of the application-level transparency. This tool tries to find a compromise between these two goals and attempts to support high-level of universality with minimizing the impact on the application itself.
	The project needs to do some trade-offs between the application-level transparency and the universality of the platform. The goal is to be able to instrument JVM-based applications to minimize the impact on the application's code itself.
	\item \textbf{Easiness of Use} \newline
	The application should use high-level programming language for the instrumentation and specifying additional information to be collected. The users of this tool are supposed to work with Java-based language and should not be required to have deeper knowledge about internal Java Virtual Machine structure.
	\item \textbf{Easiness of Deployment} \newline
	The complexity of deployment of this tool is also a significant aspect of the tool. In order for developers and testers to use this tool frequently, its deployment and usage has to be relatively easy. This requirement has two sub-parts. Minimizing the configuration of the monitoring tool to the bare minimum and also minimizing the number of artifacts users of this tool are required to use.
	\item \textbf{Modularity} \newline
	The Distrace tool should be designed in a way that some parts of the whole tool may be substituted by user specific modules. For example, the users should be allowed to switch the default user interface to the user interface they prefer without significantly affecting the code of the tool.
\end{itemize}

The discussion of different approaches for meeting the requirements above are discussed in the Chapter \ref{analysis}.

\section{Thesis Outline}
The thesis starts with the background in the Chapter \ref{chap:background}. The purpose of this chapter is to give the reader overview of relevant tools to the thesis such as list of several profiling tools, instrumentation and communication libraries. It also describes the relevant cluster monitoring tools like Google Dapper and OpenZipkin in more details. The following Chapter \ref{analysis} contains analysis of the solution and discussion of how specific requirements of the thesis are met. It also mentions the weaknesses of the relevant cluster monitoring tools and describes how the thesis tries to overcome some of the issues. The following Chapter \ref{chap:design} contains design of Distrace. It starts with the Section \ref{design:overview} describing overview of the whole tool and depicting the architecture of the whole system. This section is followed by the Section \ref{design:use_case} demonstrating a simple use case for this tool. Further, the Chapter \ref{design:overview} contains sections for each important part of the application such as explanation of spans in the Section \ref{subsec:spans}, the instrumentation server in the Section \ref{sec:inst_server}, the native agent in the Section \ref{native_agent_design} and the user interface in the Section \ref{sec:zipkin_ui}. The next Chapter \ref{chap:implementation} describes several interesting implementation details in more depth and is followed by the Chapter \ref{chap:big_example}. The purpose of this chapter is to show a more complex example of how Distrace can be used, in this case on the H2O machine learning platform. The task is to visualize the hierarchy of internal map-reduce calls inside the H2O platform and also to see how long each map and reduce operation last. The last Chapter \ref{chap:evaluation} mentions the current limitations of the tool and also compares different deployment strategies of Distrace and give the comparisons between them.
